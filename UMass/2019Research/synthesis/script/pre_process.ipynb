{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from functools import reduce\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_json(json_path):\n",
    "    img_id2cat_id = defaultdict(list)\n",
    "    \n",
    "    json_data = json.load(open(json_path))\n",
    "    image_ids = [im['id'] for im in json_data['images']]    \n",
    "    catid2name = {category['id']: category['name'] for category in json_data['categories']}\n",
    "    idx2catid = [catid for catid in catid2name]\n",
    "    catid2idx = {catid: idx for idx, catid in enumerate(idx2catid)}\n",
    "    \n",
    "    for anno in json_data['annotations']:\n",
    "        if anno['category_id'] not in img_id2cat_id[anno['image_id']]:\n",
    "            img_id2cat_id[int(anno['image_id'])].append(anno['category_id'])\n",
    "    # print('number of images with annotations', len(img_id2cat_id))\n",
    "    return img_id2cat_id, catid2name, catid2idx, idx2catid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only test on validation now. Training file too big need to use cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img_id2cat_id, catid2name, catid2idx, idx2catid = read_from_json('../mscoco/annotations/instances_val2017.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_id2cat_id, _, _, _ = read_from_json('../mscoco/annotations/instances_train2017.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n"
     ]
    }
   ],
   "source": [
    "print(catid2name[idx2catid[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 191013\n",
    "# i = 191288\n",
    "# i = 191471\n",
    "# i = 191580\n",
    "# i = 191614\n",
    "# i = 191672\n",
    "# i = 191761\n",
    "# i = 191845\n",
    "###\n",
    "for single_cat_id in img_id2cat_id[i]:\n",
    "    print(catid2name[single_cat_id])\n",
    "    print(catid2idx[single_cat_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************\n",
      "191731\n",
      "banana\n",
      "cat id 52\n",
      "46\n",
      "******************************\n",
      "191126\n",
      "bird\n",
      "cat id 16\n",
      "14\n",
      "******************************\n",
      "191873\n",
      "truck\n",
      "cat id 8\n",
      "7\n",
      "******************************\n",
      "191873\n",
      "traffic light\n",
      "cat id 10\n",
      "9\n",
      "******************************\n",
      "191873\n",
      "person\n",
      "cat id 1\n",
      "0\n",
      "******************************\n",
      "191873\n",
      "car\n",
      "cat id 3\n",
      "2\n",
      "******************************\n",
      "191296\n",
      "fire hydrant\n",
      "cat id 11\n",
      "10\n",
      "******************************\n",
      "191639\n",
      "cell phone\n",
      "cat id 77\n",
      "67\n",
      "******************************\n",
      "191639\n",
      "person\n",
      "cat id 1\n",
      "0\n",
      "******************************\n",
      "191376\n",
      "car\n",
      "cat id 3\n",
      "2\n",
      "******************************\n",
      "191376\n",
      "bus\n",
      "cat id 6\n",
      "5\n",
      "******************************\n",
      "191376\n",
      "person\n",
      "cat id 1\n",
      "0\n",
      "******************************\n",
      "191376\n",
      "traffic light\n",
      "cat id 10\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for i in [191731,191126,191873,191296,191639,191376]:\n",
    "    for single_cat_id in train_img_id2cat_id[i]:\n",
    "        print('*'*30)\n",
    "        print(i)\n",
    "        print(catid2name[single_cat_id])\n",
    "        print('cat id',single_cat_id)\n",
    "        print(catid2idx[single_cat_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use caption, time permitted\n",
    "# cooc_from_json('../mscoco/annotations/captions_val2017.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# supress tensorflow logging other than errors\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "print(tf.__version__)\n",
    "# 1.1.0\n",
    "\n",
    "x = tf.placeholder(tf.int32, [5])\n",
    "y = tf.placeholder(tf.int32, [5])\n",
    "acc, acc_op = tf.metrics.accuracy(labels=x, predictions=y)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.26666668]\n",
      "0.26666668\n"
     ]
    }
   ],
   "source": [
    "# sess.run(tf.global_variables_initializer())\n",
    "# sess.run(tf.local_variables_initializer())\n",
    "v = sess.run([acc, acc_op], feed_dict={x: [1, 0, 0, 0, 0],\n",
    "                                       y: [1, 0, 0, 0, 1]})\n",
    "print(v)\n",
    "# [0.0, 0.8]\n",
    "\n",
    "v = sess.run(acc)\n",
    "print(v)\n",
    "# 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sess.run(tf.local_variables_initializer())\n",
    "v = sess.run([acc, acc_op], feed_dict={x: [1, 0, 0, 0, 0],\n",
    "                                       y: [0, 1, 1, 1, 1]})\n",
    "print(v)\n",
    "# [0.8, 0.4]\n",
    "\n",
    "v = sess.run(acc)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "v = sess.run([acc, acc_op], feed_dict={x: [1, 0, 0, 0, 0],\n",
    "                                       y: [0, 1, 1, 1, 1]})\n",
    "print(v)\n",
    "# [0.8, 0.4]\n",
    "\n",
    "v = sess.run(acc)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "y_true = np.array([[2, 1], [1, 2], [0, 1], [3, 1], [0, 1]]).astype(np.int64)\n",
    "# y_true = np.array([[0,0,1,0], [0,1,0,0], [1,0,0,0], [0,0,0,1], [1,0,0,0]]).astype(np.int64)\n",
    "y_true = tf.identity(y_true)\n",
    "\n",
    "y_pred = np.array([[0.1, 0.2, 0.6, 0.1],\n",
    "                   [0.8, 0.05, 0.1, 0.05],\n",
    "                   [0.3, 0.4, 0.1, 0.2],\n",
    "                   [0.6, 0.25, 0.1, 0.05],\n",
    "                   [0.1, 0.2, 0.6, 0.1]\n",
    "                   ]).astype(np.float32)\n",
    "y_pred = tf.identity(y_pred)\n",
    "\n",
    "_, m_ap = tf.metrics.sparse_average_precision_at_k(y_true, y_pred, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 3)\n",
      "[[  4  40 400]\n",
      " [  5  50 500]\n",
      " [  6  60 600]\n",
      " [  7  70 700]\n",
      " [  4  40 400]\n",
      " [  5  50 500]\n",
      " [  6  60 600]\n",
      " [  7  70 700]\n",
      " [  4  40 400]\n",
      " [  5  50 500]\n",
      " [  6  60 600]\n",
      " [  7  70 700]]\n",
      "(12, 3)\n",
      "[[  1  10 100]\n",
      " [  1  10 100]\n",
      " [  1  10 100]\n",
      " [  1  10 100]\n",
      " [  2  20 200]\n",
      " [  2  20 200]\n",
      " [  2  20 200]\n",
      " [  2  20 200]\n",
      " [  3  30 300]\n",
      " [  3  30 300]\n",
      " [  3  30 300]\n",
      " [  3  30 300]]\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[1, 10, 100],[2, 20, 200],[3, 30, 300]]) \n",
    "b = tf.constant([[4, 40, 400],[5, 50, 500],[6, 60, 600],[7, 70,700]]) \n",
    "\n",
    "tile_a = tf.tile(tf.expand_dims(a, 1), [1, tf.shape(b)[0], 1])  \n",
    "tile_a = tf.reshape(tile_a, [-1, tf.shape(a)[1]])\n",
    "\n",
    "tile_b = tf.tile(tf.expand_dims(b, 0), [tf.shape(a)[0], 1, 1]) \n",
    "tile_b = tf.reshape(tile_b, [-1, tf.shape(b)[1]])\n",
    "\n",
    "# cartesian_product = tf.concat([tile_a, tile_b], axis=2) \n",
    "# cartesian_product = tf.reshape(cartesian_product, [-1, tf.shape(cartesian_product)[2], tf.shape(a)[1])\n",
    "# cartesian_product = tf.transpose(cartesian_product, [1, 0, 2])\n",
    "\n",
    "tile_a = tf.reshape(tile_a, [-1])\n",
    "tile_a = tf.reshape(tile_a, [-1, 3])\n",
    "\n",
    "cart = tf.Session().run(tile_a) \n",
    "tileb = tf.Session().run(tile_b)\n",
    "# cart = tf.Session().run(tile_a)\n",
    "print(tileb.shape)\n",
    "print(tileb)\n",
    "\n",
    "\n",
    "print(cart.shape) \n",
    "print(cart) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sess = tf.Session()\n",
    "sess.run(tf.local_variables_initializer())\n",
    "\n",
    "stream_vars = [i for i in tf.local_variables()]\n",
    "\n",
    "tf_map = sess.run(m_ap)\n",
    "print(tf_map)\n",
    "\n",
    "# print((sess.run(stream_vars)))\n",
    "\n",
    "# tmp_rank = tf.nn.top_k(y_pred,3)\n",
    "\n",
    "# print(sess.run(tmp_rank)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3_7",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
